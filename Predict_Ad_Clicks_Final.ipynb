{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Ad Clicks\n",
    "https://www.hackerearth.com/challenge/competitive/machine-learning-challenge-3/problems/\n",
    "Leaderboard: 10th position"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Reqd modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score as ruc\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0)\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputing missing values and Handling timeseries data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "# imputing missing values\n",
    "train['siteid'].fillna(-999, inplace=True)\n",
    "test['siteid'].fillna(-999, inplace=True)\n",
    "\n",
    "train['browserid'].fillna(\"None\",inplace=True)\n",
    "test['browserid'].fillna(\"None\", inplace=True)\n",
    "\n",
    "train['devid'].fillna(\"None\",inplace=True)\n",
    "test['devid'].fillna(\"None\",inplace=True)\n",
    "\n",
    "# create timebased features\n",
    "\n",
    "train['datetime'] = pd.to_datetime(train['datetime'])\n",
    "test['datetime'] = pd.to_datetime(test['datetime'])\n",
    "\n",
    "train['tweekday'] = train['datetime'].dt.weekday\n",
    "test['tweekday'] = test['datetime'].dt.weekday\n",
    "\n",
    "train['thour'] = train['datetime'].dt.hour\n",
    "test['thour'] = test['datetime'].dt.hour\n",
    "\n",
    "train['tminute'] = train['datetime'].dt.minute\n",
    "test['tminute'] = test['datetime'].dt.minute\n",
    "\n",
    "# create aggregate features\n",
    "site_offer_count = train.groupby(['siteid','offerid']).size().reset_index()\n",
    "site_offer_count.columns = ['siteid','offerid','site_offer_count']\n",
    "\n",
    "site_offer_count_test = test.groupby(['siteid','offerid']).size().reset_index()\n",
    "site_offer_count_test.columns = ['siteid','offerid','site_offer_count']\n",
    "\n",
    "site_cat_count = train.groupby(['siteid','category']).size().reset_index()\n",
    "site_cat_count.columns = ['siteid','category','site_cat_count']\n",
    "\n",
    "site_cat_count_test = test.groupby(['siteid','category']).size().reset_index()\n",
    "site_cat_count_test.columns = ['siteid','category','site_cat_count']\n",
    "\n",
    "site_mcht_count = train.groupby(['siteid','merchant']).size().reset_index()\n",
    "site_mcht_count.columns = ['siteid','merchant','site_mcht_count']\n",
    "\n",
    "site_mcht_count_test = test.groupby(['siteid','merchant']).size().reset_index()\n",
    "site_mcht_count_test.columns = ['siteid','merchant','site_mcht_count']\n",
    "\n",
    "# joining all files\n",
    "agg_df = [site_offer_count,site_cat_count,site_mcht_count]\n",
    "agg_df_test = [site_offer_count_test,site_cat_count_test,site_mcht_count_test]\n",
    "\n",
    "for x in agg_df:\n",
    "    train = train.merge(x)\n",
    "    \n",
    "for x in agg_df_test:\n",
    "    test = test.merge(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = train.sample(1500000)\n",
    "print (train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting dtype of columns into object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numeric_data = train.select_dtypes(include=[np.number])\n",
    "cat_data = train.select_dtypes(exclude=[np.number])\n",
    "print(\"There are {} numeric and {} categorical columns in train data\".format(numeric_data.shape[1],cat_data.shape[1]))\n",
    "numeric_data.drop(['site_offer_count','site_cat_count','tweekday','thour','tminute','site_mcht_count'],axis=1,inplace=True)\n",
    "for i in numeric_data.columns:\n",
    "    train[i] = train[i].astype(object)\n",
    "cat_data = train.select_dtypes(include=['object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Label Encoding\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "for c in list(train.select_dtypes(include=['object']).columns):\n",
    "    if c != 'ID' and c!='click':\n",
    "        lbl = LabelEncoder()\n",
    "        lbl.fit(list(train[c].values) + list(test[c].values))\n",
    "        train[c] = lbl.transform(list(train[c].values))\n",
    "        test[c] = lbl.transform(list(test[c].values)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_data = train.append(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_0 = train[train['click']==0]\n",
    "train_0.drop('click',axis=1,inplace=True)\n",
    "train_1 = train[train['click']==1]\n",
    "train_1.drop('click',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gp_by = ['countrycode','merchant']\n",
    "count = train_1.groupby(gp_by).size()\n",
    "count = count.to_frame()\n",
    "count.columns = ['count']\n",
    "#count = count.loc[4,'count'].to_frame()\n",
    "count = count.loc[0,'count'].sort_values(ascending=False)[1:10].to_frame()\n",
    "count.index.names = ['index']\n",
    "count['index'] = count.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#plot the  value count\n",
    "sns.set(style=\"whitegrid\", color_codes=True)\n",
    "sns.barplot(x = 'index', y = 'count',data=count)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\", color_codes=True)\n",
    "#sns.swarmplot(x=\"devid\", y=\"browserid\", hue=\"click\", data=all_data[all_data.notnull()])\n",
    "sns.countplot(x=\"merchant\", data=train_0, palette=\"Greens_d\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_data['is_cat_20'] = (all_data['category']==20)*1\n",
    "all_data['is_not_cat_117_121'] = ((all_data['category']!=117)&(all_data['category']!=121))*1\n",
    "all_data['is_country_2_3'] = ((all_data['countrycode']==2)|(all_data['countrycode']==3))*1\n",
    "all_data['is_country_not_0_1'] = ((all_data['countrycode']!=1)&(all_data['countrycode']!=0))*1\n",
    "all_data['is_country_2_browser_3'] = ((all_data['countrycode']==2)&((all_data['browserid']==3)))*1\n",
    "all_data['is_country_2_browser_not_2'] = ((all_data['countrycode']==2)&((all_data['browserid']!=2)))*1\n",
    "all_data['is_devid_not_3'] = (all_data['devid']!=3)*1\n",
    "all_data['is_devid_0'] = (all_data['devid']==0)*1\n",
    "all_data['is_browserid_not_7_8'] = ((all_data['browserid']!=7)&(all_data['browserid']!=8))*1\n",
    "all_data['is_devid_3_browser_5_11'] = ((all_data['devid']==3)&((all_data['browserid']==5)|(all_data['browserid']==11)))*1\n",
    "all_data['is_browser_not_1_2'] = ((all_data['browserid']!=1)&(all_data['browserid']!=2))*1\n",
    "all_data['is_browser_3_6'] = ((all_data['browserid']==3)|(all_data['browserid']==6))*1\n",
    "all_data['is_siteid_not_137632_22767_1466'] = ((all_data['siteid']!=137632)&(all_data['siteid']!=22767)&\n",
    "                                               (all_data['siteid']!=1466))*1\n",
    "all_data['is_siteid_4055_40767_43672'] = ((all_data['siteid']==43672)|(all_data['siteid']==4055)|(all_data['siteid']==40767))*1\n",
    "all_data['is_siteid_124622_country_5'] = ((all_data['siteid']==124622)&(all_data['countrycode']==5))*1\n",
    "all_data['is_thour_not_17'] = (all_data['thour']!=17)*1\n",
    "all_data['is_country_4_hour_not_13'] = ((all_data['countrycode']==4)&(all_data['thour']!=13))*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gp_by = 'merchant'\n",
    "count = train_1.groupby(gp_by).size()\n",
    "count = count.to_frame()\n",
    "count.columns = ['count']\n",
    "count.index.names = ['index']\n",
    "count['index'] = count.index\n",
    "count2 = count['count'].sort_values(ascending=False)[:50].index\n",
    "count0 = count['count'].sort_values()[:50].index\n",
    "def label(merch):\n",
    "    if merch in count2 and merch not in count0:\n",
    "        return 2\n",
    "    elif merch in count0 and merch not in count2:\n",
    "        return 0\n",
    "    return 1\n",
    "all_data['is_merch_bins'] = all_data[gp_by].apply(lambda row: label(row))\n",
    "all_data['is_merch_bins'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gp_by = 'category'\n",
    "count = train_1.groupby(gp_by).size()\n",
    "count = count.to_frame()\n",
    "count.columns = ['count']\n",
    "count.index.names = ['index']\n",
    "count['index'] = count.index\n",
    "count2 = count['count'].sort_values(ascending=False)[:50].index\n",
    "count0 = count['count'].sort_values()[:50].index\n",
    "def label(merch):\n",
    "    if merch in count2 and merch not in count0:\n",
    "        return 2\n",
    "    elif merch in count0 and merch not in count2:\n",
    "        return 0\n",
    "    return 1\n",
    "all_data['is_category_bins'] = all_data[gp_by].apply(lambda row: label(row))\n",
    "all_data['is_category_bins'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gp_by = 'siteid'\n",
    "count = train_1.groupby(gp_by).size()\n",
    "count = count.to_frame()\n",
    "count.columns = ['count']\n",
    "count.index.names = ['index']\n",
    "count['index'] = count.index\n",
    "count2 = count['count'].sort_values(ascending=False)[:10000].index\n",
    "count0 = count['count'].sort_values()[:10000].index\n",
    "def label(merch):\n",
    "    if merch in count2 and merch not in count0:\n",
    "        return 2\n",
    "    elif merch in count0 and merch not in count2:\n",
    "        return 0\n",
    "    return 1\n",
    "all_data['is_site_bins'] = all_data[gp_by].apply(lambda row: label(row))\n",
    "all_data['is_site_bins'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gp_by = 'offerid'\n",
    "count = train_1.groupby(gp_by).size()\n",
    "count = count.to_frame()\n",
    "count.columns = ['count']\n",
    "count.index.names = ['index']\n",
    "count['index'] = count.index\n",
    "count2 = count['count'].sort_values(ascending=False)[:10000].index\n",
    "count0 = count['count'].sort_values()[:10000].index\n",
    "def label(merch):\n",
    "    if merch in count2 and merch not in count0:\n",
    "        return 2\n",
    "    elif merch in count0 and merch not in count2:\n",
    "        return 0\n",
    "    return 1\n",
    "all_data['is_offer_bins'] = all_data[gp_by].apply(lambda row: label(row))\n",
    "all_data['is_offer_bins'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting Data and one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_new = all_data[all_data['click'].notnull()]\n",
    "test_new = all_data[all_data['click'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def onehot(onehot_df,df,column_name):\n",
    "       onehot_df[column_name] = df[column_name]\n",
    "       dummies = pd.get_dummies(onehot_df[column_name], prefix=\"_\"+column_name)\n",
    "       onehot_df = onehot_df.join(dummies)\n",
    "       onehot_df = onehot_df.drop([column_name], axis=1)\n",
    "       return onehot_df\n",
    "\n",
    "def munge_onehot(df):\n",
    "       onehot_df = pd.DataFrame(index = df.index)\n",
    "       onehot_df = onehot(onehot_df, df, \"countrycode\")\n",
    "       onehot_df = onehot(onehot_df, df, \"browserid\")\n",
    "       onehot_df = onehot(onehot_df, df, \"devid\")\n",
    "       onehot_df = onehot(onehot_df, df, \"thour\")\n",
    "       onehot_df = onehot(onehot_df, df, \"tweekday\")\n",
    "       return onehot_df\n",
    "\n",
    "#create one-hot features\n",
    "onehot_df = munge_onehot(train)\n",
    "train_new = train_new.join(onehot_df) \n",
    "onehot_df = munge_onehot(test)\n",
    "test_new = test_new.join(onehot_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating training-testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target = train_new['click']\n",
    "test_new_ID = test_new.ID\n",
    "train_new.drop(['click','datetime','ID','_tweekday_1', '_tweekday_2', '_tweekday_3', '_tweekday_4'],axis=1,inplace=True)\n",
    "test_new.drop(['click','datetime','ID'],axis=1,inplace=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_new, target, test_size = 0.5,random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training, prediciting,saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import roc_auc_score as ruc\n",
    "model = CatBoostClassifier(depth=9,iterations=100,learning_rate=0.1,od_pval=0.01,eval_metric='AUC',random_seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.fit(X_train\n",
    "          ,y_train\n",
    "          ,cat_features=[0,1,2,3,4,5,9,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33]\n",
    "          ,eval_set = (X_test, y_test)\n",
    "          ,use_best_model=True\n",
    "          ,verbose=True\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = model.predict_proba(test_new)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub = pd.DataFrame({'ID':test_new_ID,'click':pred})\n",
    "sub.to_csv('cb_20.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
